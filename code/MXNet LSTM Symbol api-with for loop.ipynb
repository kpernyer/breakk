{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilbe\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.utils import PROJECT_DATA_DIR\n",
    "import os\n",
    "import mxnet as mx\n",
    "import mxnet.ndarray as nd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "from load_preprocess import (load_data,\n",
    "                             get_xy,\n",
    "                             scale_data,\n",
    "                             binarize_y,\n",
    "                             prepare_data)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",  category=DeprecationWarning)\n",
    "from DL_mxnet_symbol import train_dnn, train_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "train = load_data(file='all_training_400_minisensor_1.csv')\n",
    "test = load_data(file='all_test_400_minisensor.csv')\n",
    "xtrain, ytrain = get_xy(train)\n",
    "xtest, ytest = get_xy(test)\n",
    "ytrain = binarize_y(ytrain, arg_list=[1])\n",
    "print(ytrain.unique())\n",
    "ytest = binarize_y(ytest, arg_list=[1])\n",
    "\n",
    "xtrain_sc, xtest_sc = scale_data(xtrain, xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1191</th>\n",
       "      <th>1192</th>\n",
       "      <th>1193</th>\n",
       "      <th>1194</th>\n",
       "      <th>1195</th>\n",
       "      <th>1196</th>\n",
       "      <th>1197</th>\n",
       "      <th>1198</th>\n",
       "      <th>1199</th>\n",
       "      <th>1200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-4</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-7</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-7</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>-5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-4</td>\n",
       "      <td>-4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...   1191  \\\n",
       "0    -3     3     4    -3     3     4     1    -3     2     0  ...      0   \n",
       "1     3     0     0     1     0     0     0     2     0     0  ...     -1   \n",
       "2     1    -3     7     0     1     4    -3     4     0    -2  ...     -4   \n",
       "3     4     1    -1     3     4    -8     3     4    -1     3  ...      0   \n",
       "4     0    -4     0     5     0     0     5     0    -5     0  ...      0   \n",
       "\n",
       "   1192  1193  1194  1195  1196  1197  1198  1199  1200  \n",
       "0     0     0     3     0    -4    -2     0    -5     8  \n",
       "1     0    -7     3    -1    -7     7    -1    -5     7  \n",
       "2     1     8    -2     1    12     0     4    11     4  \n",
       "3     4    -5    -1     3     6     3     4     7     6  \n",
       "4    -4    -4     3     3     0     4     3     1     8  \n",
       "\n",
       "[5 rows x 1201 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1191</th>\n",
       "      <th>1192</th>\n",
       "      <th>1193</th>\n",
       "      <th>1194</th>\n",
       "      <th>1195</th>\n",
       "      <th>1196</th>\n",
       "      <th>1197</th>\n",
       "      <th>1198</th>\n",
       "      <th>1199</th>\n",
       "      <th>1200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>-13</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>-8</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>51</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-4</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>-4</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-8</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>18</td>\n",
       "      <td>-57</td>\n",
       "      <td>48</td>\n",
       "      <td>-3</td>\n",
       "      <td>-148</td>\n",
       "      <td>37</td>\n",
       "      <td>-33</td>\n",
       "      <td>-241</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-17</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-17</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-21</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>-3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...   1191  \\\n",
       "0     1    -1    -1     0     2    -1    -2     2     1    -2  ...     -2   \n",
       "1     3     6   -13     3     6    -8     3     6    -2    -1  ...     -1   \n",
       "2    -1     2    -1     2     0    -1    -4    -3     0    -4  ...     -1   \n",
       "3    48    18   -57    48    -3  -148    37   -33  -241    29  ...      4   \n",
       "4    -2    -2     0     0    -3     1    -3     0     0     3  ...      0   \n",
       "\n",
       "   1192  1193  1194  1195  1196  1197  1198  1199  1200  \n",
       "0    -3     0     0     0     1     0     2     0     8  \n",
       "1     7    44    14     7    51    23    11    59     6  \n",
       "2     0    -1    -1     0    -8    -3     0    -3     5  \n",
       "3     0   -17     9     0   -17     6     0   -21     8  \n",
       "4     0     4     0    -3     6     3    -3     4     8  \n",
       "\n",
       "[5 rows x 1201 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD8CAYAAACCRVh7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkan/B52+QNvDJrupAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f0cba59c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD9CAYAAABX0LttAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8QsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f09278b0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtrain[xtrain.columns[0]].plot()\n",
    "plt.show()\n",
    "ytrain.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((91104,), (22776,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ytrain.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain_mx = mx.nd.array(xtrain_sc, dtype=np.float32)\n",
    "ytrain_mx = mx.nd.array(ytrain.reshape(-1, 1))\n",
    "xtest_mx = mx.nd.array(xtest_sc, dtype=np.float32)\n",
    "ytest_mx = mx.nd.array(ytest.reshape(-1, 1))\n",
    "batch_size=2**9\n",
    "\n",
    "train_iter = mx.io.NDArrayIter(\n",
    "    xtrain_mx,\n",
    "    ytrain_mx,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "val_iter = mx.io.NDArrayIter(\n",
    "    xtest_mx,\n",
    "    ytest_mx,\n",
    "    batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Already bound, ignoring bind()\n",
      "WARNING:root:optimizer already initialized, ignoring...\n",
      "INFO:root:Epoch[0] Batch [100]\tSpeed: 123703.55 samples/sec\taccuracy=0.941097\n",
      "INFO:root:Epoch[0] Train-accuracy=0.937373\n",
      "INFO:root:Epoch[0] Time cost=0.821\n",
      "INFO:root:Epoch[0] Validation-accuracy=0.938802\n",
      "INFO:root:Epoch[1] Batch [100]\tSpeed: 115363.70 samples/sec\taccuracy=0.941097\n",
      "INFO:root:Epoch[1] Train-accuracy=0.937424\n",
      "INFO:root:Epoch[1] Time cost=0.783\n",
      "INFO:root:Epoch[1] Validation-accuracy=0.938889\n",
      "INFO:root:Epoch[2] Batch [100]\tSpeed: 115620.03 samples/sec\taccuracy=0.941155\n",
      "INFO:root:Epoch[2] Train-accuracy=0.938464\n",
      "INFO:root:Epoch[2] Time cost=0.791\n",
      "INFO:root:Epoch[2] Validation-accuracy=0.940061\n",
      "INFO:root:Epoch[3] Batch [100]\tSpeed: 111361.13 samples/sec\taccuracy=0.941909\n",
      "INFO:root:Epoch[3] Train-accuracy=0.939352\n",
      "INFO:root:Epoch[3] Time cost=0.805\n",
      "INFO:root:Epoch[3] Validation-accuracy=0.940321\n",
      "INFO:root:Epoch[4] Batch [100]\tSpeed: 110880.10 samples/sec\taccuracy=0.942547\n",
      "INFO:root:Epoch[4] Train-accuracy=0.940874\n",
      "INFO:root:Epoch[4] Time cost=0.818\n",
      "INFO:root:Epoch[4] Validation-accuracy=0.939497\n",
      "INFO:root:Epoch[5] Batch [100]\tSpeed: 110640.28 samples/sec\taccuracy=0.941754\n",
      "INFO:root:Epoch[5] Train-accuracy=0.940214\n",
      "INFO:root:Epoch[5] Time cost=0.817\n",
      "INFO:root:Epoch[5] Validation-accuracy=0.943793\n",
      "INFO:root:Epoch[6] Batch [100]\tSpeed: 106951.72 samples/sec\taccuracy=0.945158\n",
      "INFO:root:Epoch[6] Train-accuracy=0.939453\n",
      "INFO:root:Epoch[6] Time cost=0.849\n",
      "INFO:root:Epoch[6] Validation-accuracy=0.941623\n",
      "INFO:root:Epoch[7] Batch [100]\tSpeed: 106508.27 samples/sec\taccuracy=0.942857\n",
      "INFO:root:Epoch[7] Train-accuracy=0.942243\n",
      "INFO:root:Epoch[7] Time cost=0.869\n",
      "INFO:root:Epoch[7] Validation-accuracy=0.939540\n",
      "INFO:root:Epoch[8] Batch [100]\tSpeed: 108305.34 samples/sec\taccuracy=0.946918\n",
      "INFO:root:Epoch[8] Train-accuracy=0.941761\n",
      "INFO:root:Epoch[8] Time cost=0.840\n",
      "INFO:root:Epoch[8] Validation-accuracy=0.946354\n",
      "INFO:root:Epoch[9] Batch [100]\tSpeed: 110879.93 samples/sec\taccuracy=0.963393\n",
      "INFO:root:Epoch[9] Train-accuracy=0.947595\n",
      "INFO:root:Epoch[9] Time cost=0.821\n",
      "INFO:root:Epoch[9] Validation-accuracy=0.948003\n",
      "INFO:root:Epoch[10] Batch [100]\tSpeed: 104984.68 samples/sec\taccuracy=0.955890\n",
      "INFO:root:Epoch[10] Train-accuracy=0.952745\n",
      "INFO:root:Epoch[10] Time cost=0.845\n",
      "INFO:root:Epoch[10] Validation-accuracy=0.953125\n",
      "INFO:root:Epoch[11] Batch [100]\tSpeed: 108306.05 samples/sec\taccuracy=0.957631\n",
      "INFO:root:Epoch[11] Train-accuracy=0.939326\n",
      "INFO:root:Epoch[11] Time cost=0.850\n",
      "INFO:root:Epoch[11] Validation-accuracy=0.941753\n",
      "INFO:root:Epoch[12] Batch [100]\tSpeed: 113829.27 samples/sec\taccuracy=0.944056\n",
      "INFO:root:Epoch[12] Train-accuracy=0.955433\n",
      "INFO:root:Epoch[12] Time cost=0.801\n",
      "INFO:root:Epoch[12] Validation-accuracy=0.950043\n",
      "INFO:root:Epoch[13] Batch [100]\tSpeed: 107624.14 samples/sec\taccuracy=0.952738\n",
      "INFO:root:Epoch[13] Train-accuracy=0.952186\n",
      "INFO:root:Epoch[13] Time cost=0.821\n",
      "INFO:root:Epoch[13] Validation-accuracy=0.940061\n",
      "INFO:root:Epoch[14] Batch [100]\tSpeed: 107175.37 samples/sec\taccuracy=0.949180\n",
      "INFO:root:Epoch[14] Train-accuracy=0.945490\n",
      "INFO:root:Epoch[14] Time cost=0.829\n",
      "INFO:root:Epoch[14] Validation-accuracy=0.938802\n",
      "INFO:root:Epoch[15] Batch [100]\tSpeed: 110640.06 samples/sec\taccuracy=0.950224\n",
      "INFO:root:Epoch[15] Train-accuracy=0.950538\n",
      "INFO:root:Epoch[15] Time cost=0.832\n",
      "INFO:root:Epoch[15] Validation-accuracy=0.961589\n",
      "INFO:root:Epoch[16] Batch [100]\tSpeed: 110640.00 samples/sec\taccuracy=0.971013\n",
      "INFO:root:Epoch[16] Train-accuracy=0.964590\n",
      "INFO:root:Epoch[16] Time cost=0.823\n",
      "INFO:root:Epoch[16] Validation-accuracy=0.958290\n",
      "INFO:root:Epoch[17] Batch [100]\tSpeed: 108305.72 samples/sec\taccuracy=0.959042\n",
      "INFO:root:Epoch[17] Train-accuracy=0.956448\n",
      "INFO:root:Epoch[17] Time cost=0.846\n",
      "INFO:root:Epoch[17] Validation-accuracy=0.961328\n",
      "INFO:root:Epoch[18] Batch [100]\tSpeed: 111848.22 samples/sec\taccuracy=0.954479\n",
      "INFO:root:Epoch[18] Train-accuracy=0.937373\n",
      "INFO:root:Epoch[18] Time cost=0.812\n",
      "INFO:root:Epoch[18] Validation-accuracy=0.938802\n",
      "INFO:root:Epoch[19] Batch [100]\tSpeed: 106950.71 samples/sec\taccuracy=0.941097\n",
      "INFO:root:Epoch[19] Train-accuracy=0.937373\n",
      "INFO:root:Epoch[19] Time cost=0.837\n",
      "INFO:root:Epoch[19] Validation-accuracy=0.938802\n"
     ]
    }
   ],
   "source": [
    "train_dnn(train_iter, val_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36441600, 3)\n",
      "(9110400, 3)\n",
      "shape of xtrain_lstm_sc: (91104, 400, 3)\n"
     ]
    }
   ],
   "source": [
    "xtrain_lstm = xtrain.values.reshape(-1, 3)\n",
    "xtest_lstm = xtest.values.reshape(-1, 3)\n",
    "scaler = QuantileTransformer(output_distribution='normal')\n",
    "xtrain_lstm_sc = scaler.fit_transform(xtrain_lstm)\n",
    "xtest_lstm_sc = scaler.transform(xtest_lstm)\n",
    "\n",
    "print(xtrain_lstm_sc.shape)\n",
    "print(xtest_lstm_sc.shape)\n",
    "\"\"\" Change time steps from 400 to 20 to test if this is the problem\"\"\"\n",
    "xtrain_lstm_sc = mx.nd.array(xtrain_lstm_sc.reshape(-1, 400, 3))\n",
    "val_lstm_sc = mx.nd.array(xtest_lstm_sc.reshape(-1, 400, 3))\n",
    "print('shape of xtrain_lstm_sc:', xtrain_lstm_sc.shape)\n",
    "\n",
    "train_lstm_iter = mx.io.NDArrayIter(\n",
    "    xtrain_lstm_sc,\n",
    "    ytrain_mx,\n",
    "    batch_size,\n",
    "    shuffle=True,\n",
    "    last_batch_handle='discard')\n",
    "\n",
    "val_lstm_iter = mx.io.NDArrayIter(\n",
    "    val_lstm_sc,\n",
    "    ytest_mx,\n",
    "    batch_size,\n",
    "    shuffle=False,\n",
    "    last_batch_handle='discard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## This line is erroneuous\n",
    "#train_lstm(train_lstm_iter, val_lstm_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stacked_rnn_cells = mx.rnn.SequentialRNNCell()\n",
    "#stacked_rnn_cells.add(mx.rnn.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_fused(timesteps=400, \n",
    "              num_layers=3, \n",
    "              mode='lstm', \n",
    "              num_hidden=20,\n",
    "              dropout=0.4,\n",
    "              num_outputs=1, \n",
    "              batch_size=2**9, \n",
    "              input_dim=3):\n",
    "    \n",
    "    data = mx.sym.Variable('data')\n",
    "    \"\"\" Reshape input \"\"\"\n",
    "    input_shape = (timesteps, batch_size, input_dim)\n",
    "    data = mx.sym.Reshape(data, shape=input_shape)\n",
    "    \n",
    "    \"\"\"num_hidden: number of units in output symbol\"\"\"\n",
    "    for i in range(num_layers):\n",
    "        \"\"\" Check if data is flowing correctly trough\n",
    "        the network\"\"\"\n",
    "        outputs = data # this ensures right data flows \n",
    "                        # through the network\n",
    "        fused_lstm_cell = mx.rnn.FusedRNNCell(\n",
    "            num_hidden=num_hidden, \n",
    "            dropout=dropout)\n",
    "        \"\"\" Implement many layers with for-loop as it is\n",
    "        more effective when using multiple gpus\"\"\"\n",
    "        outputs, _  = fused_lstm_cell.unroll(\n",
    "            length=timesteps, \n",
    "            inputs=outputs, \n",
    "            merge_outputs=True)\n",
    "        \"\"\" Reshape output from LSTM\"\"\"\n",
    "    output_shape = (batch_size, timesteps, num_hidden)\n",
    "    outputs = mx.sym.Reshape(outputs, shape=output_shape)\n",
    "    outputs = mx.sym.Dropout(outputs, p=dropout)\n",
    "    outputs = mx.sym.FullyConnected(\n",
    "        data=outputs, \n",
    "        name='out', \n",
    "        num_hidden=num_outputs)\n",
    "    outputs = mx.sym.LogisticRegressionOutput(\n",
    "        outputs,\n",
    "        name='softmax')\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Already bound, ignoring bind()\n",
      "WARNING:root:optimizer already initialized, ignoring...\n",
      "INFO:root:Epoch[0] Batch [100]\tSpeed: 15015.19 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[0] Train-f1=0.000000\n",
      "INFO:root:Epoch[0] Time cost=6.085\n",
      "INFO:root:Epoch[0] Validation-f1=0.000000\n",
      "INFO:root:Epoch[1] Batch [100]\tSpeed: 15006.41 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[1] Train-f1=0.000000\n",
      "INFO:root:Epoch[1] Time cost=6.079\n",
      "INFO:root:Epoch[1] Validation-f1=0.000000\n",
      "INFO:root:Epoch[2] Batch [100]\tSpeed: 15050.40 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[2] Train-f1=0.000000\n",
      "INFO:root:Epoch[2] Time cost=6.053\n",
      "INFO:root:Epoch[2] Validation-f1=0.000000\n",
      "INFO:root:Epoch[3] Batch [100]\tSpeed: 15041.60 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[3] Train-f1=0.000000\n",
      "INFO:root:Epoch[3] Time cost=6.043\n",
      "INFO:root:Epoch[3] Validation-f1=0.000000\n",
      "INFO:root:Epoch[4] Batch [100]\tSpeed: 14936.55 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[4] Train-f1=0.000000\n",
      "INFO:root:Epoch[4] Time cost=6.073\n",
      "INFO:root:Epoch[4] Validation-f1=0.000000\n",
      "INFO:root:Epoch[5] Batch [100]\tSpeed: 15028.36 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[5] Train-f1=0.000000\n",
      "INFO:root:Epoch[5] Time cost=6.058\n",
      "INFO:root:Epoch[5] Validation-f1=0.000000\n",
      "INFO:root:Epoch[6] Batch [100]\tSpeed: 15017.27 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[6] Train-f1=0.000000\n",
      "INFO:root:Epoch[6] Time cost=6.066\n",
      "INFO:root:Epoch[6] Validation-f1=0.000000\n",
      "INFO:root:Epoch[7] Batch [100]\tSpeed: 14901.87 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[7] Train-f1=0.000000\n",
      "INFO:root:Epoch[7] Time cost=6.113\n",
      "INFO:root:Epoch[7] Validation-f1=0.000000\n",
      "INFO:root:Epoch[8] Batch [100]\tSpeed: 14910.53 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[8] Train-f1=0.000000\n",
      "INFO:root:Epoch[8] Time cost=6.135\n",
      "INFO:root:Epoch[8] Validation-f1=0.000000\n",
      "INFO:root:Epoch[9] Batch [100]\tSpeed: 14910.52 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[9] Train-f1=0.000000\n",
      "INFO:root:Epoch[9] Time cost=6.109\n",
      "INFO:root:Epoch[9] Validation-f1=0.000000\n",
      "INFO:root:Epoch[10] Batch [100]\tSpeed: 14971.41 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[10] Train-f1=0.000000\n",
      "INFO:root:Epoch[10] Time cost=6.100\n",
      "INFO:root:Epoch[10] Validation-f1=0.000000\n",
      "INFO:root:Epoch[11] Batch [100]\tSpeed: 14901.87 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[11] Train-f1=0.000000\n",
      "INFO:root:Epoch[11] Time cost=6.105\n",
      "INFO:root:Epoch[11] Validation-f1=0.000000\n",
      "INFO:root:Epoch[12] Batch [100]\tSpeed: 14932.21 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[12] Train-f1=0.000000\n",
      "INFO:root:Epoch[12] Time cost=6.094\n",
      "INFO:root:Epoch[12] Validation-f1=0.000000\n",
      "INFO:root:Epoch[13] Batch [100]\tSpeed: 15029.88 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[13] Train-f1=0.000000\n",
      "INFO:root:Epoch[13] Time cost=6.044\n",
      "INFO:root:Epoch[13] Validation-f1=0.000000\n",
      "INFO:root:Epoch[14] Batch [100]\tSpeed: 15046.00 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[14] Train-f1=0.000000\n",
      "INFO:root:Epoch[14] Time cost=6.080\n",
      "INFO:root:Epoch[14] Validation-f1=0.000000\n",
      "INFO:root:Epoch[15] Batch [100]\tSpeed: 14940.90 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[15] Train-f1=0.000000\n",
      "INFO:root:Epoch[15] Time cost=6.129\n",
      "INFO:root:Epoch[15] Validation-f1=0.000000\n",
      "INFO:root:Epoch[16] Batch [100]\tSpeed: 14760.48 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[16] Train-f1=0.000000\n",
      "INFO:root:Epoch[16] Time cost=6.186\n",
      "INFO:root:Epoch[16] Validation-f1=0.000000\n",
      "INFO:root:Epoch[17] Batch [100]\tSpeed: 14722.38 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[17] Train-f1=0.000000\n",
      "INFO:root:Epoch[17] Time cost=6.189\n",
      "INFO:root:Epoch[17] Validation-f1=0.000000\n",
      "INFO:root:Epoch[18] Batch [100]\tSpeed: 14790.24 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[18] Train-f1=0.000000\n",
      "INFO:root:Epoch[18] Time cost=6.182\n",
      "INFO:root:Epoch[18] Validation-f1=0.000000\n",
      "INFO:root:Epoch[19] Batch [100]\tSpeed: 14319.75 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[19] Train-f1=0.000000\n",
      "INFO:root:Epoch[19] Time cost=6.346\n",
      "INFO:root:Epoch[19] Validation-f1=0.000000\n"
     ]
    }
   ],
   "source": [
    "net = rnn_fused()\n",
    "train_iter.reset()\n",
    "val_iter.reset()\n",
    "mod = mx.mod.Module(net, context=mx.gpu())\n",
    "mod.bind(data_shapes=train_lstm_iter.provide_data, \n",
    "        label_shapes=train_lstm_iter.provide_label)\n",
    "mod.init_params(initializer=mx.init.Xavier())\n",
    "mod.init_optimizer(\n",
    "            optimizer='sgd',\n",
    "optimizer_params=(('learning_rate', 0.01), ))\n",
    "\n",
    "mod.fit(train_data=train_iter,\n",
    "        eval_data=val_iter,\n",
    "        #optimizer='s',\n",
    "        #optimizer_params={'learning_rate': 0.01},\n",
    "        eval_metric='f1',\n",
    "        num_epoch=20,\n",
    "        batch_end_callback = mx.callback.Speedometer(batch_size, 100),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "from mxnet_models import eval_metrics\n",
    "\n",
    "def train(timesteps=400, num_layers=3, \n",
    "          mode='lstm', num_hidden=20, \n",
    "          dropout=0.4, num_outputs=1, \n",
    "          batch_size=2**9, input_dim=3, \n",
    "          learning_rate=0.01, num_epoch=20):\n",
    "    \n",
    "    train_lstm_iter = mx.io.NDArrayIter(\n",
    "        xtrain_lstm_sc,\n",
    "        ytrain_mx,\n",
    "        batch_size,\n",
    "        shuffle=True,\n",
    "        last_batch_handle='discard')\n",
    "    \n",
    "    val_lstm_iter = mx.io.NDArrayIter(\n",
    "        val_lstm_sc,\n",
    "        ytest_mx,\n",
    "        batch_size,\n",
    "        shuffle=False,\n",
    "        last_batch_handle='discard')\n",
    "    \n",
    "    train_lstm_iter.reset()\n",
    "    val_lstm_iter.reset()\n",
    "\n",
    "    net = rnn_fused(timesteps=timesteps, \n",
    "                    num_layers=num_layers, \n",
    "                    num_hidden=num_hidden, \n",
    "                    dropout=dropout, \n",
    "                    num_outputs=num_outputs, \n",
    "                    batch_size=batch_size, \n",
    "                    input_dim=input_dim)\n",
    "    \n",
    "    mod = mx.mod.Module(net, context=mx.gpu())\n",
    "    mod.bind(data_shapes=train_lstm_iter.provide_data, \n",
    "             label_shapes=train_lstm_iter.provide_label)\n",
    "    \n",
    "    mod.init_params(initializer=mx.init.Xavier())\n",
    "    mod.init_optimizer(\n",
    "        optimizer='sgd',\n",
    "        optimizer_params=(('learning_rate', learning_rate), ))\n",
    "\n",
    "    mod.fit(\n",
    "        train_data=train_lstm_iter,\n",
    "        eval_data=train_lstm_iter,\n",
    "        eval_metric='f1',\n",
    "        num_epoch=num_epoch,\n",
    "        batch_end_callback = mx.callback.Speedometer(\n",
    "        batch_size, 100))\n",
    "    \n",
    "    f1_train = mod.score(val_lstm_iter, 'f1')\n",
    "    f1_test = mod.score(val_lstm_iter, 'f1')\n",
    "    print('f1_train:', f1_train)\n",
    "    print('f1_test:', f1_test)\n",
    "        \n",
    "    return f1_train[0][1], f1_test[0][1]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "while loop no: 0\n",
      "\n",
      "\n",
      "{'num_epoch': 16, 'num_hidden': 38, 'timesteps': 400, 'learning_rate': 0.005822306974333445, 'num_outputs': 1, 'batch_size': 512, 'input_dim': 3, 'num_layers': 4, 'dropout': 0.193703910196925}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Already bound, ignoring bind()\n",
      "WARNING:root:optimizer already initialized, ignoring...\n",
      "INFO:root:Epoch[0] Batch [100]\tSpeed: 10689.64 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[0] Train-f1=0.000000\n",
      "INFO:root:Epoch[0] Time cost=8.462\n",
      "INFO:root:Epoch[0] Validation-f1=0.000000\n",
      "INFO:root:Epoch[1] Batch [100]\tSpeed: 10805.93 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[1] Train-f1=0.000000\n",
      "INFO:root:Epoch[1] Time cost=8.370\n",
      "INFO:root:Epoch[1] Validation-f1=0.000000\n",
      "INFO:root:Epoch[2] Batch [100]\tSpeed: 10697.47 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[2] Train-f1=0.000000\n",
      "INFO:root:Epoch[2] Time cost=8.485\n",
      "INFO:root:Epoch[2] Validation-f1=0.000000\n",
      "INFO:root:Epoch[3] Batch [100]\tSpeed: 10514.37 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[3] Train-f1=0.000000\n",
      "INFO:root:Epoch[3] Time cost=8.610\n",
      "INFO:root:Epoch[3] Validation-f1=0.000000\n",
      "INFO:root:Epoch[4] Batch [100]\tSpeed: 10411.99 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[4] Train-f1=0.000000\n",
      "INFO:root:Epoch[4] Time cost=8.715\n",
      "INFO:root:Epoch[4] Validation-f1=0.000000\n",
      "INFO:root:Epoch[5] Batch [100]\tSpeed: 10084.43 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[5] Train-f1=0.000000\n",
      "INFO:root:Epoch[5] Time cost=8.966\n",
      "INFO:root:Epoch[5] Validation-f1=0.000000\n",
      "INFO:root:Epoch[6] Batch [100]\tSpeed: 10159.53 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[6] Train-f1=0.000000\n",
      "INFO:root:Epoch[6] Time cost=8.955\n",
      "INFO:root:Epoch[6] Validation-f1=0.000000\n",
      "INFO:root:Epoch[7] Batch [100]\tSpeed: 10130.48 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[7] Train-f1=0.000000\n",
      "INFO:root:Epoch[7] Time cost=8.912\n",
      "INFO:root:Epoch[7] Validation-f1=0.000000\n",
      "INFO:root:Epoch[8] Batch [100]\tSpeed: 10103.92 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[8] Train-f1=0.000000\n",
      "INFO:root:Epoch[8] Time cost=8.893\n",
      "INFO:root:Epoch[8] Validation-f1=0.000000\n",
      "INFO:root:Epoch[9] Batch [100]\tSpeed: 10172.30 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[9] Train-f1=0.000000\n",
      "INFO:root:Epoch[9] Time cost=8.923\n",
      "INFO:root:Epoch[9] Validation-f1=0.000000\n",
      "INFO:root:Epoch[10] Batch [100]\tSpeed: 10064.66 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[10] Train-f1=0.000000\n",
      "INFO:root:Epoch[10] Time cost=8.959\n",
      "INFO:root:Epoch[10] Validation-f1=0.000000\n",
      "INFO:root:Epoch[11] Batch [100]\tSpeed: 10136.02 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[11] Train-f1=0.000000\n",
      "INFO:root:Epoch[11] Time cost=8.897\n",
      "INFO:root:Epoch[11] Validation-f1=0.000000\n",
      "INFO:root:Epoch[12] Batch [100]\tSpeed: 10227.20 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[12] Train-f1=0.000000\n",
      "INFO:root:Epoch[12] Time cost=8.836\n",
      "INFO:root:Epoch[12] Validation-f1=0.000000\n",
      "INFO:root:Epoch[13] Batch [100]\tSpeed: 10194.84 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[13] Train-f1=0.000000\n",
      "INFO:root:Epoch[13] Time cost=8.880\n",
      "INFO:root:Epoch[13] Validation-f1=0.000000\n",
      "INFO:root:Epoch[14] Batch [100]\tSpeed: 10088.20 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[14] Train-f1=0.000000\n",
      "INFO:root:Epoch[14] Time cost=8.937\n",
      "INFO:root:Epoch[14] Validation-f1=0.000000\n",
      "INFO:root:Epoch[15] Batch [100]\tSpeed: 10169.86 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[15] Train-f1=0.000000\n",
      "INFO:root:Epoch[15] Time cost=8.902\n",
      "INFO:root:Epoch[15] Validation-f1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_train: [('f1', 0.0)]\n",
      "f1_test: [('f1', 0.0)]\n",
      "while loop no: 1\n",
      "\n",
      "\n",
      "{'num_epoch': 16, 'num_hidden': 21, 'timesteps': 400, 'learning_rate': 0.001979039741642425, 'num_outputs': 1, 'batch_size': 512, 'input_dim': 3, 'num_layers': 4, 'dropout': 0.23030882906767267}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Already bound, ignoring bind()\n",
      "WARNING:root:optimizer already initialized, ignoring...\n",
      "INFO:root:Epoch[0] Batch [100]\tSpeed: 14181.47 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[0] Train-f1=0.000000\n",
      "INFO:root:Epoch[0] Time cost=6.409\n",
      "INFO:root:Epoch[0] Validation-f1=0.000000\n",
      "INFO:root:Epoch[1] Batch [100]\tSpeed: 13774.27 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[1] Train-f1=0.000000\n",
      "INFO:root:Epoch[1] Time cost=6.570\n",
      "INFO:root:Epoch[1] Validation-f1=0.000000\n",
      "INFO:root:Epoch[2] Batch [100]\tSpeed: 13620.32 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[2] Train-f1=0.000000\n",
      "INFO:root:Epoch[2] Time cost=6.640\n",
      "INFO:root:Epoch[2] Validation-f1=0.000000\n",
      "INFO:root:Epoch[3] Batch [100]\tSpeed: 13889.87 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[3] Train-f1=0.000000\n",
      "INFO:root:Epoch[3] Time cost=6.470\n",
      "INFO:root:Epoch[3] Validation-f1=0.000000\n",
      "INFO:root:Epoch[4] Batch [100]\tSpeed: 13626.91 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[4] Train-f1=0.000000\n",
      "INFO:root:Epoch[4] Time cost=6.640\n",
      "INFO:root:Epoch[4] Validation-f1=0.000000\n",
      "INFO:root:Epoch[5] Batch [100]\tSpeed: 12015.83 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[5] Train-f1=0.000000\n",
      "INFO:root:Epoch[5] Time cost=7.565\n",
      "INFO:root:Epoch[5] Validation-f1=0.000000\n",
      "INFO:root:Epoch[6] Batch [100]\tSpeed: 12625.91 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[6] Train-f1=0.000000\n",
      "INFO:root:Epoch[6] Time cost=7.226\n",
      "INFO:root:Epoch[6] Validation-f1=0.000000\n",
      "INFO:root:Epoch[7] Batch [100]\tSpeed: 13599.19 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[7] Train-f1=0.000000\n",
      "INFO:root:Epoch[7] Time cost=6.598\n",
      "INFO:root:Epoch[7] Validation-f1=0.000000\n",
      "INFO:root:Epoch[8] Batch [100]\tSpeed: 13927.55 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[8] Train-f1=0.000000\n",
      "INFO:root:Epoch[8] Time cost=6.524\n",
      "INFO:root:Epoch[8] Validation-f1=0.000000\n",
      "INFO:root:Epoch[9] Batch [100]\tSpeed: 13844.92 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[9] Train-f1=0.000000\n",
      "INFO:root:Epoch[9] Time cost=6.573\n",
      "INFO:root:Epoch[9] Validation-f1=0.000000\n",
      "INFO:root:Epoch[10] Batch [100]\tSpeed: 11782.64 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[10] Train-f1=0.000000\n",
      "INFO:root:Epoch[10] Time cost=7.639\n",
      "INFO:root:Epoch[10] Validation-f1=0.000000\n",
      "INFO:root:Epoch[11] Batch [100]\tSpeed: 11940.34 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[11] Train-f1=0.000000\n",
      "INFO:root:Epoch[11] Time cost=7.529\n",
      "INFO:root:Epoch[11] Validation-f1=0.000000\n",
      "INFO:root:Epoch[12] Batch [100]\tSpeed: 13826.27 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[12] Train-f1=0.000000\n",
      "INFO:root:Epoch[12] Time cost=6.624\n",
      "INFO:root:Epoch[12] Validation-f1=0.000000\n",
      "INFO:root:Epoch[13] Batch [100]\tSpeed: 13599.11 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[13] Train-f1=0.000000\n",
      "INFO:root:Epoch[13] Time cost=6.597\n",
      "INFO:root:Epoch[13] Validation-f1=0.000000\n",
      "INFO:root:Epoch[14] Batch [100]\tSpeed: 13737.73 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[14] Train-f1=0.000000\n",
      "INFO:root:Epoch[14] Time cost=6.610\n",
      "INFO:root:Epoch[14] Validation-f1=0.000000\n",
      "INFO:root:Epoch[15] Batch [100]\tSpeed: 13705.17 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[15] Train-f1=0.000000\n",
      "INFO:root:Epoch[15] Time cost=6.539\n",
      "INFO:root:Epoch[15] Validation-f1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_train: [('f1', 0.0)]\n",
      "f1_test: [('f1', 0.0)]\n",
      "while loop no: 2\n",
      "\n",
      "\n",
      "{'num_epoch': 17, 'num_hidden': 23, 'timesteps': 400, 'learning_rate': 0.00029792477345854556, 'num_outputs': 1, 'batch_size': 512, 'input_dim': 3, 'num_layers': 4, 'dropout': 0.4334867738934043}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Already bound, ignoring bind()\n",
      "WARNING:root:optimizer already initialized, ignoring...\n",
      "INFO:root:Epoch[0] Batch [100]\tSpeed: 12901.97 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[0] Train-f1=0.000000\n",
      "INFO:root:Epoch[0] Time cost=6.995\n",
      "INFO:root:Epoch[0] Validation-f1=0.000000\n",
      "INFO:root:Epoch[1] Batch [100]\tSpeed: 13474.27 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[1] Train-f1=0.000000\n",
      "INFO:root:Epoch[1] Time cost=6.748\n",
      "INFO:root:Epoch[1] Validation-f1=0.000000\n",
      "INFO:root:Epoch[2] Batch [100]\tSpeed: 12999.56 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[2] Train-f1=0.000000\n",
      "INFO:root:Epoch[2] Time cost=6.987\n",
      "INFO:root:Epoch[2] Validation-f1=0.000000\n",
      "INFO:root:Epoch[3] Batch [100]\tSpeed: 12967.15 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[3] Train-f1=0.000000\n",
      "INFO:root:Epoch[3] Time cost=6.978\n",
      "INFO:root:Epoch[3] Validation-f1=0.000000\n",
      "INFO:root:Epoch[4] Batch [100]\tSpeed: 13365.51 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[4] Train-f1=0.000000\n",
      "INFO:root:Epoch[4] Time cost=6.802\n",
      "INFO:root:Epoch[4] Validation-f1=0.000000\n",
      "INFO:root:Epoch[5] Batch [100]\tSpeed: 12555.86 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[5] Train-f1=0.000000\n",
      "INFO:root:Epoch[5] Time cost=7.339\n",
      "INFO:root:Epoch[5] Validation-f1=0.000000\n",
      "INFO:root:Epoch[6] Batch [100]\tSpeed: 11097.02 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[6] Train-f1=0.000000\n",
      "INFO:root:Epoch[6] Time cost=8.868\n",
      "INFO:root:Epoch[6] Validation-f1=0.000000\n",
      "INFO:root:Epoch[7] Batch [100]\tSpeed: 8351.98 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[7] Train-f1=0.000000\n",
      "INFO:root:Epoch[7] Time cost=10.695\n",
      "INFO:root:Epoch[7] Validation-f1=0.000000\n",
      "INFO:root:Epoch[8] Batch [100]\tSpeed: 11329.33 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[8] Train-f1=0.000000\n",
      "INFO:root:Epoch[8] Time cost=7.996\n",
      "INFO:root:Epoch[8] Validation-f1=0.000000\n",
      "INFO:root:Epoch[9] Batch [100]\tSpeed: 11446.40 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[9] Train-f1=0.000000\n",
      "INFO:root:Epoch[9] Time cost=7.990\n",
      "INFO:root:Epoch[9] Validation-f1=0.000000\n",
      "INFO:root:Epoch[10] Batch [100]\tSpeed: 11812.46 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[10] Train-f1=0.000000\n",
      "INFO:root:Epoch[10] Time cost=8.801\n",
      "INFO:root:Epoch[10] Validation-f1=0.000000\n",
      "INFO:root:Epoch[11] Batch [100]\tSpeed: 8578.36 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[11] Train-f1=0.000000\n",
      "INFO:root:Epoch[11] Time cost=10.813\n",
      "INFO:root:Epoch[11] Validation-f1=0.000000\n",
      "INFO:root:Epoch[12] Batch [100]\tSpeed: 11596.32 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[12] Train-f1=0.000000\n",
      "INFO:root:Epoch[12] Time cost=8.028\n",
      "INFO:root:Epoch[12] Validation-f1=0.000000\n",
      "INFO:root:Epoch[13] Batch [100]\tSpeed: 11659.54 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[13] Train-f1=0.000000\n",
      "INFO:root:Epoch[13] Time cost=8.018\n",
      "INFO:root:Epoch[13] Validation-f1=0.000000\n",
      "INFO:root:Epoch[14] Batch [100]\tSpeed: 6991.47 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[14] Train-f1=0.000000\n",
      "INFO:root:Epoch[14] Time cost=11.246\n",
      "INFO:root:Epoch[14] Validation-f1=0.000000\n",
      "INFO:root:Epoch[15] Batch [100]\tSpeed: 10307.73 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[15] Train-f1=0.000000\n",
      "INFO:root:Epoch[15] Time cost=8.911\n",
      "INFO:root:Epoch[15] Validation-f1=0.000000\n",
      "INFO:root:Epoch[16] Batch [100]\tSpeed: 10509.10 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[16] Train-f1=0.000000\n",
      "INFO:root:Epoch[16] Time cost=8.809\n",
      "INFO:root:Epoch[16] Validation-f1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_train: [('f1', 0.0)]\n",
      "f1_test: [('f1', 0.0)]\n",
      "while loop no: 3\n",
      "\n",
      "\n",
      "{'num_epoch': 13, 'num_hidden': 25, 'timesteps': 400, 'learning_rate': 0.006453298054111103, 'num_outputs': 1, 'batch_size': 512, 'input_dim': 3, 'num_layers': 3, 'dropout': 0.3143550747593378}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Already bound, ignoring bind()\n",
      "WARNING:root:optimizer already initialized, ignoring...\n",
      "INFO:root:Epoch[0] Batch [100]\tSpeed: 8932.83 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[0] Train-f1=0.000000\n",
      "INFO:root:Epoch[0] Time cost=10.272\n",
      "INFO:root:Epoch[0] Validation-f1=0.000000\n",
      "INFO:root:Epoch[1] Batch [100]\tSpeed: 8921.96 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[1] Train-f1=0.000000\n",
      "INFO:root:Epoch[1] Time cost=9.496\n",
      "INFO:root:Epoch[1] Validation-f1=0.000000\n",
      "INFO:root:Epoch[2] Batch [100]\tSpeed: 10855.82 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[2] Train-f1=0.000000\n",
      "INFO:root:Epoch[2] Time cost=8.407\n",
      "INFO:root:Epoch[2] Validation-f1=0.000000\n",
      "INFO:root:Epoch[3] Batch [100]\tSpeed: 8602.39 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[3] Train-f1=0.000000\n",
      "INFO:root:Epoch[3] Time cost=10.642\n",
      "INFO:root:Epoch[3] Validation-f1=0.000000\n",
      "INFO:root:Epoch[4] Batch [100]\tSpeed: 9752.60 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[4] Train-f1=0.000000\n",
      "INFO:root:Epoch[4] Time cost=9.028\n",
      "INFO:root:Epoch[4] Validation-f1=0.000000\n",
      "INFO:root:Epoch[5] Batch [100]\tSpeed: 10522.07 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[5] Train-f1=0.000000\n",
      "INFO:root:Epoch[5] Time cost=8.672\n",
      "INFO:root:Epoch[5] Validation-f1=0.000000\n",
      "INFO:root:Epoch[6] Batch [100]\tSpeed: 10686.29 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[6] Train-f1=0.000000\n",
      "INFO:root:Epoch[6] Time cost=8.587\n",
      "INFO:root:Epoch[6] Validation-f1=0.000000\n",
      "INFO:root:Epoch[7] Batch [100]\tSpeed: 9383.07 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[7] Train-f1=0.000000\n",
      "INFO:root:Epoch[7] Time cost=10.821\n",
      "INFO:root:Epoch[7] Validation-f1=0.000000\n",
      "INFO:root:Epoch[8] Batch [100]\tSpeed: 11179.65 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[8] Train-f1=0.000000\n",
      "INFO:root:Epoch[8] Time cost=7.913\n",
      "INFO:root:Epoch[8] Validation-f1=0.000000\n",
      "INFO:root:Epoch[9] Batch [100]\tSpeed: 5129.77 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[9] Train-f1=0.000000\n",
      "INFO:root:Epoch[9] Time cost=18.953\n",
      "INFO:root:Epoch[9] Validation-f1=0.000000\n",
      "INFO:root:Epoch[10] Batch [100]\tSpeed: 3802.46 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[10] Train-f1=0.000000\n",
      "INFO:root:Epoch[10] Time cost=23.656\n",
      "INFO:root:Epoch[10] Validation-f1=0.000000\n",
      "INFO:root:Epoch[11] Batch [100]\tSpeed: 3772.05 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[11] Train-f1=0.000000\n",
      "INFO:root:Epoch[11] Time cost=23.883\n",
      "INFO:root:Epoch[11] Validation-f1=0.000000\n",
      "INFO:root:Epoch[12] Batch [100]\tSpeed: 3811.42 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[12] Train-f1=0.000000\n",
      "INFO:root:Epoch[12] Time cost=23.799\n",
      "INFO:root:Epoch[12] Validation-f1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_train: [('f1', 0.0)]\n",
      "f1_test: [('f1', 0.0)]\n",
      "while loop no: 4\n",
      "\n",
      "\n",
      "{'num_epoch': 19, 'num_hidden': 1, 'timesteps': 400, 'learning_rate': 0.00045359016838177345, 'num_outputs': 1, 'batch_size': 512, 'input_dim': 3, 'num_layers': 4, 'dropout': 0.14890176340947403}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Already bound, ignoring bind()\n",
      "WARNING:root:optimizer already initialized, ignoring...\n",
      "INFO:root:Epoch[0] Batch [100]\tSpeed: 10600.21 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[0] Train-f1=0.000000\n",
      "INFO:root:Epoch[0] Time cost=7.452\n",
      "INFO:root:Epoch[0] Validation-f1=0.000000\n",
      "INFO:root:Epoch[1] Batch [100]\tSpeed: 17968.82 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[1] Train-f1=0.000000\n",
      "INFO:root:Epoch[1] Time cost=5.057\n",
      "INFO:root:Epoch[1] Validation-f1=0.000000\n",
      "INFO:root:Epoch[2] Batch [100]\tSpeed: 18393.74 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[2] Train-f1=0.000000\n",
      "INFO:root:Epoch[2] Time cost=4.972\n",
      "INFO:root:Epoch[2] Validation-f1=0.000000\n",
      "INFO:root:Epoch[3] Batch [100]\tSpeed: 18880.82 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[3] Train-f1=0.000000\n",
      "INFO:root:Epoch[3] Time cost=4.858\n",
      "INFO:root:Epoch[3] Validation-f1=0.000000\n",
      "INFO:root:Epoch[4] Batch [100]\tSpeed: 18070.03 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[4] Train-f1=0.000000\n",
      "INFO:root:Epoch[4] Time cost=5.072\n",
      "INFO:root:Epoch[4] Validation-f1=0.000000\n",
      "INFO:root:Epoch[5] Batch [100]\tSpeed: 18393.74 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[5] Train-f1=0.000000\n",
      "INFO:root:Epoch[5] Time cost=4.962\n",
      "INFO:root:Epoch[5] Validation-f1=0.000000\n",
      "INFO:root:Epoch[6] Batch [100]\tSpeed: 18936.53 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[6] Train-f1=0.000000\n",
      "INFO:root:Epoch[6] Time cost=4.797\n",
      "INFO:root:Epoch[6] Validation-f1=0.000000\n",
      "INFO:root:Epoch[7] Batch [100]\tSpeed: 18887.68 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[7] Train-f1=0.000000\n",
      "INFO:root:Epoch[7] Time cost=4.813\n",
      "INFO:root:Epoch[7] Validation-f1=0.000000\n",
      "INFO:root:Epoch[8] Batch [100]\tSpeed: 18108.26 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[8] Train-f1=0.000000\n",
      "INFO:root:Epoch[8] Time cost=4.932\n",
      "INFO:root:Epoch[8] Validation-f1=0.000000\n",
      "INFO:root:Epoch[9] Batch [100]\tSpeed: 18708.80 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[9] Train-f1=0.000000\n",
      "INFO:root:Epoch[9] Time cost=4.856\n",
      "INFO:root:Epoch[9] Validation-f1=0.000000\n",
      "INFO:root:Epoch[10] Batch [100]\tSpeed: 18406.93 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[10] Train-f1=0.000000\n",
      "INFO:root:Epoch[10] Time cost=4.942\n",
      "INFO:root:Epoch[10] Validation-f1=0.000000\n",
      "INFO:root:Epoch[11] Batch [100]\tSpeed: 18674.79 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[11] Train-f1=0.000000\n",
      "INFO:root:Epoch[11] Time cost=4.828\n",
      "INFO:root:Epoch[11] Validation-f1=0.000000\n",
      "INFO:root:Epoch[12] Batch [100]\tSpeed: 18853.09 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[12] Train-f1=0.000000\n",
      "INFO:root:Epoch[12] Time cost=4.800\n",
      "INFO:root:Epoch[12] Validation-f1=0.000000\n",
      "INFO:root:Epoch[13] Batch [100]\tSpeed: 18513.13 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[13] Train-f1=0.000000\n",
      "INFO:root:Epoch[13] Time cost=4.914\n",
      "INFO:root:Epoch[13] Validation-f1=0.000000\n",
      "INFO:root:Epoch[14] Batch [100]\tSpeed: 18146.67 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[14] Train-f1=0.000000\n",
      "INFO:root:Epoch[14] Time cost=4.982\n",
      "INFO:root:Epoch[14] Validation-f1=0.000000\n",
      "INFO:root:Epoch[15] Batch [100]\tSpeed: 18191.69 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[15] Train-f1=0.000000\n",
      "INFO:root:Epoch[15] Time cost=4.938\n",
      "INFO:root:Epoch[15] Validation-f1=0.000000\n",
      "INFO:root:Epoch[16] Batch [100]\tSpeed: 18420.13 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[16] Train-f1=0.000000\n",
      "INFO:root:Epoch[16] Time cost=4.929\n",
      "INFO:root:Epoch[16] Validation-f1=0.000000\n",
      "INFO:root:Epoch[17] Batch [100]\tSpeed: 18640.87 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[17] Train-f1=0.000000\n",
      "INFO:root:Epoch[17] Time cost=4.871\n",
      "INFO:root:Epoch[17] Validation-f1=0.000000\n",
      "INFO:root:Epoch[18] Batch [100]\tSpeed: 18406.94 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[18] Train-f1=0.000000\n",
      "INFO:root:Epoch[18] Time cost=4.931\n",
      "INFO:root:Epoch[18] Validation-f1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_train: [('f1', 0.0)]\n",
      "f1_test: [('f1', 0.0)]\n",
      "while loop no: 5\n",
      "\n",
      "\n",
      "{'num_epoch': 10, 'num_hidden': 39, 'timesteps': 400, 'learning_rate': 0.003260189789817027, 'num_outputs': 1, 'batch_size': 512, 'input_dim': 3, 'num_layers': 3, 'dropout': 0.11010295473848096}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Already bound, ignoring bind()\n",
      "WARNING:root:optimizer already initialized, ignoring...\n",
      "INFO:root:Epoch[0] Batch [100]\tSpeed: 4388.06 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[0] Train-f1=0.000000\n",
      "INFO:root:Epoch[0] Time cost=15.912\n",
      "INFO:root:Epoch[0] Validation-f1=0.000000\n",
      "INFO:root:Epoch[1] Batch [100]\tSpeed: 9986.49 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[1] Train-f1=0.000000\n",
      "INFO:root:Epoch[1] Time cost=9.075\n",
      "INFO:root:Epoch[1] Validation-f1=0.000000\n",
      "INFO:root:Epoch[2] Batch [100]\tSpeed: 9975.68 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[2] Train-f1=0.000000\n",
      "INFO:root:Epoch[2] Time cost=9.123\n",
      "INFO:root:Epoch[2] Validation-f1=0.000000\n",
      "INFO:root:Epoch[3] Batch [100]\tSpeed: 9824.51 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[3] Train-f1=0.000000\n",
      "INFO:root:Epoch[3] Time cost=9.210\n",
      "INFO:root:Epoch[3] Validation-f1=0.000000\n",
      "INFO:root:Epoch[4] Batch [100]\tSpeed: 9823.86 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[4] Train-f1=0.000000\n",
      "INFO:root:Epoch[4] Time cost=9.215\n",
      "INFO:root:Epoch[4] Validation-f1=0.000000\n",
      "INFO:root:Epoch[5] Batch [100]\tSpeed: 9780.29 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[5] Train-f1=0.000000\n",
      "INFO:root:Epoch[5] Time cost=9.218\n",
      "INFO:root:Epoch[5] Validation-f1=0.000000\n",
      "INFO:root:Epoch[6] Batch [100]\tSpeed: 9772.34 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[6] Train-f1=0.000000\n",
      "INFO:root:Epoch[6] Time cost=9.227\n",
      "INFO:root:Epoch[6] Validation-f1=0.000000\n",
      "INFO:root:Epoch[7] Batch [100]\tSpeed: 9802.90 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[7] Train-f1=0.000000\n",
      "INFO:root:Epoch[7] Time cost=9.229\n",
      "INFO:root:Epoch[7] Validation-f1=0.000000\n",
      "INFO:root:Epoch[8] Batch [100]\tSpeed: 9815.24 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[8] Train-f1=0.000000\n",
      "INFO:root:Epoch[8] Time cost=9.200\n",
      "INFO:root:Epoch[8] Validation-f1=0.000000\n",
      "INFO:root:Epoch[9] Batch [100]\tSpeed: 9856.74 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[9] Train-f1=0.000000\n",
      "INFO:root:Epoch[9] Time cost=9.191\n",
      "INFO:root:Epoch[9] Validation-f1=0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_train: [('f1', 0.0)]\n",
      "f1_test: [('f1', 0.0)]\n",
      "while loop no: 6\n",
      "\n",
      "\n",
      "{'num_epoch': 10, 'num_hidden': 32, 'timesteps': 400, 'learning_rate': 0.00768866958475322, 'num_outputs': 1, 'batch_size': 512, 'input_dim': 3, 'num_layers': 4, 'dropout': 0.3960449489656602}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Already bound, ignoring bind()\n",
      "WARNING:root:optimizer already initialized, ignoring...\n",
      "INFO:root:Epoch[0] Batch [100]\tSpeed: 7959.25 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[0] Train-f1=0.000000\n",
      "INFO:root:Epoch[0] Time cost=13.383\n",
      "INFO:root:Epoch[0] Validation-f1=0.000000\n",
      "INFO:root:Epoch[1] Batch [100]\tSpeed: 10966.42 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[1] Train-f1=0.000000\n",
      "INFO:root:Epoch[1] Time cost=8.171\n",
      "INFO:root:Epoch[1] Validation-f1=0.000000\n",
      "INFO:root:Epoch[2] Batch [100]\tSpeed: 11079.62 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[2] Train-f1=0.000000\n",
      "INFO:root:Epoch[2] Time cost=8.125\n",
      "INFO:root:Epoch[2] Validation-f1=0.000000\n",
      "INFO:root:Epoch[3] Batch [100]\tSpeed: 11089.99 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[3] Train-f1=0.000000\n",
      "INFO:root:Epoch[3] Time cost=8.179\n",
      "INFO:root:Epoch[3] Validation-f1=0.000000\n",
      "INFO:root:Epoch[4] Batch [100]\tSpeed: 10823.65 samples/sec\tf1=0.000000\n",
      "INFO:root:Epoch[4] Train-f1=0.000000\n",
      "INFO:root:Epoch[4] Time cost=8.250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-dd1d64a1fe8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mf1_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-f2fe4d068d23>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(timesteps, num_layers, mode, num_hidden, dropout, num_outputs, batch_size, input_dim, learning_rate, num_epoch)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mnum_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         batch_end_callback = mx.callback.Speedometer(\n\u001b[1;32m---> 51\u001b[1;33m         batch_size, 100))\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mf1_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_lstm_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'f1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\gilbe\\Anaconda3\\lib\\site-packages\\mxnet\\module\\base_module.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_data, eval_data, eval_metric, epoch_end_callback, batch_end_callback, kvstore, optimizer, optimizer_params, eval_end_callback, eval_batch_end_callback, initializer, arg_params, aux_params, allow_missing, force_rebind, force_init, begin_epoch, num_epoch, validation_metric, monitor)\u001b[0m\n\u001b[0;32m    526\u001b[0m                 res = self.score(eval_data, validation_metric,\n\u001b[0;32m    527\u001b[0m                                  \u001b[0mscore_end_callback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_end_callback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m                                  batch_end_callback=eval_batch_end_callback, epoch=epoch)\n\u001b[0m\u001b[0;32m    529\u001b[0m                 \u001b[1;31m#TODO: pull this into default\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\gilbe\\Anaconda3\\lib\\site-packages\\mxnet\\module\\base_module.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, eval_data, eval_metric, num_batch, batch_end_callback, score_end_callback, reset, epoch)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_end_callback\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\gilbe\\Anaconda3\\lib\\site-packages\\mxnet\\module\\module.py\u001b[0m in \u001b[0;36mupdate_metric\u001b[1;34m(self, eval_metric, labels)\u001b[0m\n\u001b[0;32m    747\u001b[0m             \u001b[0mTypically\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m         \"\"\"\n\u001b[1;32m--> 749\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exec_group\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_sync_params_from_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\gilbe\\Anaconda3\\lib\\site-packages\\mxnet\\module\\executor_group.py\u001b[0m in \u001b[0;36mupdate_metric\u001b[1;34m(self, eval_metric, labels)\u001b[0m\n\u001b[0;32m    614\u001b[0m             \u001b[0mlabels_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_slice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtexec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 616\u001b[1;33m             \u001b[0meval_metric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    617\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_bind_ith_exec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshared_group\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\gilbe\\Anaconda3\\lib\\site-packages\\mxnet\\metric.py\u001b[0m in \u001b[0;36mupdate_dict\u001b[1;34m(self, label, pred)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\gilbe\\Anaconda3\\lib\\site-packages\\mxnet\\metric.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, labels, preds)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_binary_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"macro\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\gilbe\\Anaconda3\\lib\\site-packages\\mxnet\\metric.py\u001b[0m in \u001b[0;36mupdate_binary_stats\u001b[1;34m(self, label, pred)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[0mlabel_false\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlabel_true\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrue_positives\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpred_true\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlabel_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfalse_positives\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpred_true\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlabel_false\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfalse_negatives\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpred_false\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlabel_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\gilbe\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_prod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "patience = 20\n",
    "optimal_parameters = {}\n",
    "f1_accepted = 0.6\n",
    "f1_old = 0\n",
    "count = 0\n",
    "while (count < patience):\n",
    "    print('while loop no: {}'.format(count))\n",
    "    print('')\n",
    "    params = {'timesteps': 400,\n",
    "              'num_layers': np.random.randint(2, 5), \n",
    "              'num_hidden': np.random.randint(1, 50),\n",
    "              'dropout': np.random.uniform(0.1, 0.5),\n",
    "              'num_outputs': 1, \n",
    "              'batch_size': 2**9, # does not work to change batch_size?\n",
    "              'input_dim': 3, \n",
    "              'learning_rate': 10**np.random.uniform(-4, -2), \n",
    "              'num_epoch': np.random.randint(10, 20)}\n",
    "    print('')\n",
    "    print(params)\n",
    "    f1_train, f1_test = train(**params)\n",
    "    count += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
